version: '3.8'

services:
  # =============================================================================
  # Cartonization Service - Production Configuration
  # =============================================================================
  cartonization-service:
    build:
      context: .
      dockerfile: Dockerfile
    image: paklog/cartonization-service:latest
    container_name: cartonization-service-prod
    ports:
      - "8080:8080"
    environment:
      # Spring Profiles
      SPRING_PROFILES_ACTIVE: production
      
      # Database Configuration
      SPRING_DATA_MONGODB_URI: mongodb://cartonization_user:${MONGODB_PASSWORD}@mongodb:27017/cartonization?authSource=cartonization
      
      # Redis Configuration
      SPRING_REDIS_HOST: redis
      SPRING_REDIS_PORT: 6379
      SPRING_REDIS_PASSWORD: ${REDIS_PASSWORD}
      
      # Kafka Configuration
      SPRING_KAFKA_BOOTSTRAP_SERVERS: kafka:29092
      
      # Product Catalog Integration
      PRODUCT_CATALOG_BASE_URL: ${PRODUCT_CATALOG_BASE_URL:-http://product-catalog:8080}
      
      # Security
      MANAGEMENT_ENDPOINTS_WEB_EXPOSURE_INCLUDE: health,info,metrics,prometheus
      
      # Logging
      LOGGING_LEVEL_ROOT: WARN
      LOGGING_LEVEL_COM_PAKLOG_CARTONIZATION: INFO
      LOGGING_PATTERN_CONSOLE: "%d{ISO8601} [%thread] %-5level [%X{traceId:-},%X{spanId:-}] %logger{36} - %msg%n"
      
      # JVM Configuration for Production
      JAVA_OPTS: >-
        -server
        -XX:+UseContainerSupport
        -XX:MaxRAMPercentage=70.0
        -XX:+UseG1GC
        -XX:+UseStringDeduplication
        -XX:G1HeapRegionSize=16m
        -XX:+UseCompressedOops
        -XX:+OptimizeStringConcat
        -Djava.security.egd=file:/dev/./urandom
        -Dspring.profiles.active=production
    deploy:
      resources:
        limits:
          memory: 1GB
          cpus: "1.0"
        reservations:
          memory: 512MB
          cpus: "0.5"
      restart_policy:
        condition: unless-stopped
        delay: 30s
        max_attempts: 3
        window: 120s
    depends_on:
      mongodb:
        condition: service_healthy
      redis:
        condition: service_healthy
      kafka:
        condition: service_healthy
    networks:
      - cartonization-prod-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8080/api/v1/health"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 120s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # MongoDB Database - Production Configuration
  # =============================================================================
  mongodb:
    image: mongo:7.0
    container_name: cartonization-mongodb-prod
    ports:
      - "27017:27017"
    environment:
      MONGO_INITDB_ROOT_USERNAME: ${MONGODB_ROOT_USER}
      MONGO_INITDB_ROOT_PASSWORD: ${MONGODB_ROOT_PASSWORD}
      MONGO_INITDB_DATABASE: cartonization
    volumes:
      - mongodb_prod_data:/data/db
      - mongodb_prod_config:/data/configdb
      - ./docker/mongodb/mongod.conf:/etc/mongo/mongod.conf:ro
      - ./docker/mongodb/init-mongo-prod.js:/docker-entrypoint-initdb.d/init-mongo.js:ro
    command: ["mongod", "--config", "/etc/mongo/mongod.conf"]
    deploy:
      resources:
        limits:
          memory: 2GB
          cpus: "1.0"
        reservations:
          memory: 1GB
          cpus: "0.5"
    networks:
      - cartonization-prod-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "mongosh", "--eval", "db.adminCommand('ping')"]
      interval: 30s
      timeout: 10s
      retries: 5
      start_period: 30s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # Redis Cache - Production Configuration
  # =============================================================================
  redis:
    image: redis:7.2-alpine
    container_name: cartonization-redis-prod
    ports:
      - "6379:6379"
    command: >
      redis-server
      --appendonly yes
      --appendfsync everysec
      --save 900 1
      --save 300 10
      --save 60 10000
      --requirepass ${REDIS_PASSWORD}
      --maxmemory 512mb
      --maxmemory-policy allkeys-lru
    volumes:
      - redis_prod_data:/data
      - ./docker/redis/redis.conf:/etc/redis/redis.conf:ro
    deploy:
      resources:
        limits:
          memory: 768MB
          cpus: "0.5"
        reservations:
          memory: 512MB
          cpus: "0.25"
    networks:
      - cartonization-prod-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "redis-cli", "--no-auth-warning", "-a", "${REDIS_PASSWORD}", "ping"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # Apache Kafka - Production Configuration
  # =============================================================================
  zookeeper:
    image: confluentinc/cp-zookeeper:7.5.0
    container_name: cartonization-zookeeper-prod
    environment:
      ZOOKEEPER_CLIENT_PORT: 2181
      ZOOKEEPER_TICK_TIME: 2000
      ZOOKEEPER_SYNC_LIMIT: 2
      ZOOKEEPER_INIT_LIMIT: 5
      ZOOKEEPER_MAX_CLIENT_CNXNS: 60
    volumes:
      - zookeeper_prod_data:/var/lib/zookeeper/data
      - zookeeper_prod_logs:/var/lib/zookeeper/log
    deploy:
      resources:
        limits:
          memory: 512MB
          cpus: "0.5"
        reservations:
          memory: 256MB
          cpus: "0.25"
    networks:
      - cartonization-prod-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "bash", "-c", "echo 'ruok' | nc localhost 2181"]
      interval: 30s
      timeout: 10s
      retries: 5
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  kafka:
    image: confluentinc/cp-kafka:7.5.0
    container_name: cartonization-kafka-prod
    depends_on:
      zookeeper:
        condition: service_healthy
    ports:
      - "9092:9092"
    environment:
      KAFKA_BROKER_ID: 1
      KAFKA_ZOOKEEPER_CONNECT: zookeeper:2181
      KAFKA_LISTENER_SECURITY_PROTOCOL_MAP: PLAINTEXT:PLAINTEXT,PLAINTEXT_HOST:PLAINTEXT
      KAFKA_ADVERTISED_LISTENERS: PLAINTEXT://kafka:29092,PLAINTEXT_HOST://localhost:9092
      KAFKA_INTER_BROKER_LISTENER_NAME: PLAINTEXT
      KAFKA_OFFSETS_TOPIC_REPLICATION_FACTOR: 1
      KAFKA_TRANSACTION_STATE_LOG_MIN_ISR: 1
      KAFKA_TRANSACTION_STATE_LOG_REPLICATION_FACTOR: 1
      KAFKA_GROUP_INITIAL_REBALANCE_DELAY_MS: 3000
      KAFKA_AUTO_CREATE_TOPICS_ENABLE: 'false'
      KAFKA_DEFAULT_REPLICATION_FACTOR: 1
      KAFKA_NUM_PARTITIONS: 3
      KAFKA_LOG_RETENTION_HOURS: 168
      KAFKA_LOG_SEGMENT_BYTES: 1073741824
      KAFKA_LOG_RETENTION_CHECK_INTERVAL_MS: 300000
      KAFKA_COMPRESSION_TYPE: producer
    volumes:
      - kafka_prod_data:/var/lib/kafka/data
    deploy:
      resources:
        limits:
          memory: 2GB
          cpus: "1.0"
        reservations:
          memory: 1GB
          cpus: "0.5"
    networks:
      - cartonization-prod-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "kafka-broker-api-versions", "--bootstrap-server", "localhost:29092"]
      interval: 30s
      timeout: 15s
      retries: 5
      start_period: 60s
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

  # =============================================================================
  # Nginx Reverse Proxy
  # =============================================================================
  nginx:
    image: nginx:1.25-alpine
    container_name: cartonization-nginx-prod
    ports:
      - "80:80"
      - "443:443"
    volumes:
      - ./docker/nginx/nginx.conf:/etc/nginx/nginx.conf:ro
      - ./docker/nginx/ssl:/etc/nginx/ssl:ro
      - nginx_logs:/var/log/nginx
    depends_on:
      - cartonization-service
    deploy:
      resources:
        limits:
          memory: 128MB
          cpus: "0.25"
        reservations:
          memory: 64MB
          cpus: "0.1"
    networks:
      - cartonization-prod-network
    restart: unless-stopped
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost/health"]
      interval: 30s
      timeout: 10s
      retries: 3
    logging:
      driver: "json-file"
      options:
        max-size: "10m"
        max-file: "3"

# =============================================================================
# Networks
# =============================================================================
networks:
  cartonization-prod-network:
    driver: bridge
    name: cartonization-prod-network

# =============================================================================
# Volumes
# =============================================================================
volumes:
  mongodb_prod_data:
    name: cartonization_mongodb_prod_data
    driver: local
  mongodb_prod_config:
    name: cartonization_mongodb_prod_config
    driver: local
  redis_prod_data:
    name: cartonization_redis_prod_data
    driver: local
  kafka_prod_data:
    name: cartonization_kafka_prod_data
    driver: local
  zookeeper_prod_data:
    name: cartonization_zookeeper_prod_data
    driver: local
  zookeeper_prod_logs:
    name: cartonization_zookeeper_prod_logs
    driver: local
  nginx_logs:
    name: cartonization_nginx_logs
    driver: local